# 1，系统概述

## 1.1 业务场景
对用户在网页或手机端等产生的浏览商品，购买商品行为进行分析处理。
从中获取对产品有益的数据，帮助产品更好的分析用户和推送用户想要的商品。

## 1.2 业务流程

用户的所有的行为都封装成一个事件，发送到kafka。

Flink去实时消费kafka中的数据（用户行为明细），根据给定的规则，判断是否满足，如果满足就往kafka发送一条消息，后续由业务系统进行消费。

## 1.3 规则

首先是触发条件，只有满足触发条件，才会进入规则匹配，也就是说触发条件是规则匹配的入口。

其次，是用户画像条件，比如用户性别、年龄，职业，出生地....。用户画像条件存在hbase中，根据用户Id去hbase中查询，如果满足用户画像条件，继续进行后续的规则匹配。

用户行为次数类条件，比如购买A商品的次数超过3次, B商品加入购物车的次数超过2次。

用户行为序列类条件，比如用户依次购买A商品，B商品，C 商品。

## 1.4 数据存在哪里

画像类条件查询hbase，rowkey是用户ID

行为次数类条件，如果是2小时内的，查询flink的状态。如果超过2小时，那么就从clickhouse中查询。

select 事件id, count(*) from event where userId = '' group by  事件id

行为序列类条件：A -> B -> C

# 2,  系统开发流程 (迭代式开发)
## 2.1 版本一
静态规则，规则的生成和所有的匹配流程都写在processFunction中，代码耦合性高

## 2.2 版本二
- 规则模拟放到一个工具类中
- 原子规则封装到一个bean中
```
eventId  -> 事件Id
eventProps: Map[String, String] ->  事件属性
timeRangeStart   ->  规则的查询起始时间
timeRangeEnd  ->  规则的查询结束时间
minLimit  ->  规则中要求事件需要完成的最小次数限制
maxLimit  ->  规则中要求事件需要完成的最大次数限制
```
-- 完整的规则也封装到一个bean中
```
                          /**
                           * 规则Id
                           */
                          ruleId: String,

                          /**
                           * keyby的字段, 使用逗号分割，例如:  "province,city"
                           */
                          keyByFields: String,

                          /**
                           * 规则触发条件
                           */
                          triggerEventCondition: EventCondition,

                          /**
                           * 用户画像属性条件
                           */
                          userProfileConditions: Map[String,(String, String)],

                          /**
                           * 行为次数类规则条件
                           */
                          actionCountConditionList: List[EventCondition],

                          /**
                           * 行为次序类条件
                           */
                          actionSeqConditionList: List[EventSeqCondition]
```
![规则关系1](img/ruleCondition1.png)

- 所有的规则都从clickhouse中查询

## 2.3 版本三
所有的规则匹配流程都抽离出来（封装成方法），而不是全部写在processFunction中，降低代码耦合性，提高代码可读性

## 2.4 版本四
- 版本三的不足：
1. 所有的规则查询都是请求clickhouse，会对clickhouse造成很大的压力。
clickhouse的并发不高，每秒最大支持的并发数大概只有1000到2000
2. clickhouse对实时插入支持不好，一般都是定时批量插入
- 改进：
1. 引入flink的状态，每收到一条事件数据，就插入flink的状态中
2. flink的状态设置有效期为2小时
3. 分段查询的引入

 - 1. 分界查询点的设计
 主要是为了后面的缓存考虑，具体的设计方案：
 当前时间向上取整，然后-2小时
 - 2. 具体的查询方案：
 如果规则的起始时间 >= 分界点，只查询state；
 如果规则的结束时间 < 分界点，只查询 clickhouse；
 否则，需要跨界查询